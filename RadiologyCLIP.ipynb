{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayyucedemirbas/RadiologyCLIP/blob/main/RadiologyCLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ],
      "metadata": {
        "id": "HTtaRbEhSzv2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTgnbLK7S2Wi",
        "outputId": "ee6a2c21-025c-4dd6-b49b-51fb0c4652a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-01 17:53:08--  https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz\n",
            "Resolving openi.nlm.nih.gov (openi.nlm.nih.gov)... 130.14.65.157, 2607:f220:41e:7065::157\n",
            "Connecting to openi.nlm.nih.gov (openi.nlm.nih.gov)|130.14.65.157|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1360814128 (1.3G) [application/x-gzip]\n",
            "Saving to: ‘NLMCXR_png.tgz’\n",
            "\n",
            "NLMCXR_png.tgz      100%[===================>]   1.27G  1.99MB/s    in 11m 0s  \n",
            "\n",
            "2025-02-01 18:04:08 (1.97 MB/s) - ‘NLMCXR_png.tgz’ saved [1360814128/1360814128]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://openi.nlm.nih.gov/imgs/collections/NLMCXR_reports.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf5uaJSHS-2W",
        "outputId": "d2c983c4-d9c6-40ea-b9fc-5beb0967cc54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-01 18:04:27--  https://openi.nlm.nih.gov/imgs/collections/NLMCXR_reports.tgz\n",
            "Resolving openi.nlm.nih.gov (openi.nlm.nih.gov)... 130.14.65.157, 2607:f220:41e:7065::157\n",
            "Connecting to openi.nlm.nih.gov (openi.nlm.nih.gov)|130.14.65.157|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1112632 (1.1M) [application/x-gzip]\n",
            "Saving to: ‘NLMCXR_reports.tgz’\n",
            "\n",
            "NLMCXR_reports.tgz  100%[===================>]   1.06M  1.69MB/s    in 0.6s    \n",
            "\n",
            "2025-02-01 18:04:28 (1.69 MB/s) - ‘NLMCXR_reports.tgz’ saved [1112632/1112632]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir workdir"
      ],
      "metadata": {
        "id": "0JeibBNWekj2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd workdir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlruHtxeeme3",
        "outputId": "82020089-29eb-44e0-f2a5-ebe6beddb8f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/workdir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf /content/NLMCXR_png.tgz -C .\n",
        "!tar -xvzf /content/NLMCXR_reports.tgz -C ."
      ],
      "metadata": {
        "id": "Egz8vlPCihAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUWF8ag4ijl6",
        "outputId": "2e830b7e-bcdd-4ea6-af88-5645aa00797f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv workdir/ecgen-radiology ."
      ],
      "metadata": {
        "id": "KKGa09tLiyJT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al"
      ],
      "metadata": {
        "id": "xa9oVr5_i1x1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2080fe55-f815-4f50-dbed-3fb5bf25e85b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1330472\n",
            "drwxr-xr-x 1 root root       4096 Feb  1 18:05 .\n",
            "drwxr-xr-x 1 root root       4096 Feb  1 17:48 ..\n",
            "drwxr-xr-x 4 root root       4096 Jan 30 14:18 .config\n",
            "drwxr-xr-x 2  929  212      94208 Feb  4  2016 ecgen-radiology\n",
            "-rw-r--r-- 1 root root 1360814128 Sep  6  2016 NLMCXR_png.tgz\n",
            "-rw-r--r-- 1 root root    1112632 Jun  6  2017 NLMCXR_reports.tgz\n",
            "drwxr-xr-x 1 root root       4096 Jan 30 14:19 sample_data\n",
            "drwxr-xr-x 2   48   48     352256 Feb  1 18:05 workdir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET"
      ],
      "metadata": {
        "id": "O0-d4j20inSA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_valid_pairs(image_dir='workdir', report_dir='ecgen-radiology'):\n",
        "    valid_pairs = []\n",
        "    report_files = {}\n",
        "\n",
        "    for root, _, files in os.walk(report_dir):\n",
        "        for f in files:\n",
        "            if f.lower().endswith('.xml'):\n",
        "                base_name = os.path.splitext(f)[0].lower()\n",
        "                report_files[base_name] = os.path.join(root, f)\n",
        "\n",
        "    for root, _, files in os.walk(image_dir):\n",
        "        for f in files:\n",
        "            if f.lower().endswith('.png'):\n",
        "                base_name = os.path.splitext(f)[0].lower()\n",
        "                if base_name in report_files:\n",
        "                    valid_pairs.append((\n",
        "                        os.path.join(root, f),\n",
        "                        report_files[base_name]\n",
        "                    ))\n",
        "    return valid_pairs\n",
        "\n",
        "\n",
        "def parse_xml_report(xml_path):\n",
        "    try:\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "        ns = {'pmc': 'http://www.ncbi.nlm.nih.gov/pmc/articles/PMC'}\n",
        "\n",
        "        findings_elem = root.find(\".//pmc:AbstractText[@Label='FINDINGS']\", ns)\n",
        "        impression_elem = root.find(\".//pmc:AbstractText[@Label='IMPRESSION']\", ns)\n",
        "\n",
        "        findings = findings_elem.text.strip() if (findings_elem is not None and findings_elem.text) else \"\"\n",
        "        impression = impression_elem.text.strip() if (impression_elem is not None and impression_elem.text) else \"\"\n",
        "\n",
        "        if not findings and not impression:\n",
        "            return None\n",
        "\n",
        "        return f\"FINDINGS: {findings}. IMPRESSION: {impression}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing {xml_path}: {str(e)}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "Ka7j4WAni3yp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "def parse_xml_report(xml_path):\n",
        "    try:\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "        ns = {'pmc': 'http://www.ncbi.nlm.nih.gov/pmc/articles/PMC'}\n",
        "\n",
        "        findings = root.find(\".//AbstractText[@Label='FINDINGS']\", ns)\n",
        "        impression = root.find(\".//AbstractText[@Label='IMPRESSION']\", ns)\n",
        "\n",
        "        findings_text = findings.text.strip() if (findings is not None and findings.text) else \"\"\n",
        "        impression_text = impression.text.strip() if (impression is not None and impression.text) else \"\"\n",
        "\n",
        "        if not findings_text and not impression_text:\n",
        "            return None, []\n",
        "\n",
        "        image_ids = [img.get('id') for img in root.findall('.//parentImage')]\n",
        "\n",
        "        image_paths = [f\"workdir/{img_id}.png\" for img_id in image_ids]\n",
        "\n",
        "        return (\n",
        "            f\"FINDINGS: {findings_text}. IMPRESSION: {impression_text}\",\n",
        "            image_paths\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing {xml_path}: {str(e)}\")\n",
        "        return None, []\n",
        "\n",
        "def create_dataset():\n",
        "    data = []\n",
        "\n",
        "    for root_dir, _, files in os.walk(\"ecgen-radiology\"):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.xml'):\n",
        "                xml_path = os.path.join(root_dir, file)\n",
        "                report_text, image_paths = parse_xml_report(xml_path)\n",
        "\n",
        "                if report_text and image_paths:\n",
        "                    for img_path in image_paths:\n",
        "                        if os.path.exists(img_path):\n",
        "                            data.append({\n",
        "                                'image_path': img_path,\n",
        "                                'report': report_text\n",
        "                            })\n",
        "                        else:\n",
        "                            print(f\"Missing image: {img_path}\")\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "radiology_df = create_dataset()\n",
        "print(f\"Found {len(radiology_df)} valid image-report pairs\")\n",
        "\n",
        "if not radiology_df.empty:\n",
        "    print(\"\\nSample entry:\")\n",
        "    print(f\"Image path: {radiology_df.iloc[0]['image_path']}\")\n",
        "    print(f\"Report: {radiology_df.iloc[0]['report']}\")\n",
        "else:\n",
        "    print(\"\\nNo valid pairs found. Check:\")\n",
        "    print(\"- XML files in ecgen-radiology directory\")\n",
        "    print(\"- Image files in workdir directory\")\n",
        "    print(\"- File naming consistency between XML and PNG files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjyjyp2HjClS",
        "outputId": "f38c9359-2748-49d8-bda5-9071359b4298"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7430 valid image-report pairs\n",
            "\n",
            "Sample entry:\n",
            "Image path: workdir/CXR1329_IM-0211-1001.png\n",
            "Report: FINDINGS: Two nodules are noted in the right XXXX XXXX measuring 13 mm and one measuring 16 mm in diameter. The smaller one appears to be within the right upper lobe and the large XXXX appears to be within the left lower lobe. No focal consolidation and no other pulmonary nodules are identified. However, if a full evaluation for lung nodules is desired consider XXXX for further evaluation. No pleural effusions or pneumothoraces. Heart and mediastinum of normal size and contour.. IMPRESSION: At XXXX 2 right lung pulmonary nodules concerning for<BR>metastatic disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(\n",
        "    num_words=5000,\n",
        "    oov_token=\"\",\n",
        "    filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ '\n",
        ")\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(radiology_df['report'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_length = 100\n",
        "\n",
        "\n",
        "print([word for word in tokenizer.word_index if \"pneumonia\" in word or \"effusion\" in word][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYb2IL0AjLF7",
        "outputId": "f3895f8b-cda2-477c-f458-f41433c07c43"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['effusion', 'effusions', 'pneumonia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sample(sample):\n",
        "    img = load_img(sample['image_path'], target_size=(224, 224))\n",
        "    img = img_to_array(img) / 255.0\n",
        "\n",
        "    seq = tokenizer.texts_to_sequences([sample['report']])[0]\n",
        "    seq = tf.keras.preprocessing.sequence.pad_sequences([seq], maxlen=max_length, padding='post')[0]\n",
        "    return img, seq\n",
        "\n",
        "def dataset_generator(df):\n",
        "    for idx, row in df.iterrows():\n",
        "        yield {'image_path': row['image_path'], 'report': row['report']}"
      ],
      "metadata": {
        "id": "jU7ZBCnNkA2i"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_signature = {\n",
        "    'image_path': tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "    'report': tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "}\n",
        "\n",
        "ds = tf.data.Dataset.from_generator(\n",
        "    lambda: dataset_generator(radiology_df),\n",
        "    output_signature=output_signature\n",
        ")"
      ],
      "metadata": {
        "id": "_D9vjde0kCah"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_func(image_path, report):\n",
        "    image_path = image_path.numpy().decode('utf-8')\n",
        "    report = report.numpy().decode('utf-8')\n",
        "    img, seq = preprocess_sample({'image_path': image_path, 'report': report})\n",
        "    return img, seq\n",
        "\n",
        "def tf_map_func(image_path, report):\n",
        "    img, seq = tf.py_function(\n",
        "        func=map_func,\n",
        "        inp=[image_path, report],\n",
        "        Tout=[tf.float32, tf.int32]\n",
        "    )\n",
        "    img.set_shape((224, 224, 3))\n",
        "    seq.set_shape((max_length,))\n",
        "    return img, seq"
      ],
      "metadata": {
        "id": "PdbwBiS0kHhC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "G1d7uEcmkJJg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.shuffle(buffer_size=len(radiology_df))\n",
        "ds = ds.map(lambda sample: tf_map_func(sample['image_path'], sample['report']),\n",
        "            num_parallel_calls=AUTOTUNE)\n",
        "ds = ds.batch(batch_size)\n",
        "ds = ds.prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "42dpQPw7kLGV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 256\n",
        "num_transformer_blocks = 4\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "image_size = 224"
      ],
      "metadata": {
        "id": "7VP1KQfpkjEQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_encoder(image_size):\n",
        "    inputs = layers.Input(shape=(image_size, image_size, 3))\n",
        "    patch_size = 16\n",
        "    num_patches = (image_size // patch_size) ** 2\n",
        "    projection_dim = 768\n",
        "\n",
        "    patches = layers.Conv2D(\n",
        "        filters=projection_dim,\n",
        "        kernel_size=patch_size,\n",
        "        strides=patch_size,\n",
        "        padding=\"valid\"\n",
        "    )(inputs)\n",
        "    patches = layers.Reshape((num_patches, projection_dim))(patches)\n",
        "\n",
        "    positional_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)\n",
        "    positions = tf.range(start=0, limit=num_patches, delta=1)\n",
        "    encoded_patches = patches + positional_embedding(positions)\n",
        "\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim)(x1, x1)\n",
        "        x2 = layers.Add()([x1, attention_output])\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        ffn_output = layers.Dense(ff_dim, activation=\"relu\")(x3)\n",
        "        ffn_output = layers.Dense(projection_dim)(ffn_output)\n",
        "        encoded_patches = layers.Add()([x2, ffn_output])\n",
        "\n",
        "    model = models.Model(inputs, encoded_patches, name=\"vit_encoder\")\n",
        "    return model\n",
        "\n",
        "def create_image_encoder(image_size, embedding_dim):\n",
        "    inputs = layers.Input(shape=(image_size, image_size, 3))\n",
        "    vit = create_vit_encoder(image_size)\n",
        "    x = vit(inputs)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    # Project to shared embedding dimension\n",
        "    outputs = layers.Dense(embedding_dim)(x)\n",
        "    model = models.Model(inputs, outputs, name=\"image_encoder\")\n",
        "    return model\n",
        "\n",
        "def create_text_encoder(vocab_size, embedding_dim, max_length):\n",
        "    inputs = layers.Input(shape=(max_length,))\n",
        "    x = layers.Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs)\n",
        "\n",
        "    positional_embeddings = layers.Embedding(max_length, embedding_dim)(tf.range(start=0, limit=max_length, delta=1))\n",
        "    x = x + positional_embeddings\n",
        "\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embedding_dim)(x1, x1)\n",
        "        x2 = layers.Add()([x1, attention_output])\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        ffn_output = layers.Dense(ff_dim, activation=\"relu\")(x3)\n",
        "        ffn_output = layers.Dense(embedding_dim)(ffn_output)\n",
        "        x = layers.Add()([x2, ffn_output])\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(embedding_dim)(x)\n",
        "    model = models.Model(inputs, outputs, name=\"text_encoder\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "eYnUP8LfkoDA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_encoder = create_image_encoder(image_size, embedding_dim)\n",
        "text_encoder = create_text_encoder(vocab_size, embedding_dim, max_length)"
      ],
      "metadata": {
        "id": "0gwCDiuWkqC4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CLIPModel(tf.keras.Model):\n",
        "    def __init__(self, image_encoder, text_encoder, temperature=0.05):\n",
        "        super(CLIPModel, self).__init__()\n",
        "        self.image_encoder = image_encoder\n",
        "        self.text_encoder = text_encoder\n",
        "        self.temperature = tf.Variable(temperature, trainable=True, dtype=tf.float32)\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "        super(CLIPModel, self).compile()\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        images, texts = data  # images: (batch, H, W, 3); texts: (batch, max_length)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            img_embeddings = self.image_encoder(images, training=True)\n",
        "            txt_embeddings = self.text_encoder(texts, training=True)\n",
        "\n",
        "            img_embeddings = tf.math.l2_normalize(img_embeddings, axis=1)\n",
        "            txt_embeddings = tf.math.l2_normalize(txt_embeddings, axis=1)\n",
        "\n",
        "            # Compute similarity logits: (batch, batch)\n",
        "            logits = tf.matmul(img_embeddings, txt_embeddings, transpose_b=True)\n",
        "            logits = logits / self.temperature\n",
        "\n",
        "            # Ground truth: diagonal elements are the matching pairs.\n",
        "            batch_size = tf.shape(images)[0]\n",
        "            labels = tf.range(batch_size)\n",
        "\n",
        "            # Compute cross-entropy loss for image->text and text->image\n",
        "            loss_i2t = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "            loss_t2i = tf.keras.losses.sparse_categorical_crossentropy(labels, tf.transpose(logits), from_logits=True)\n",
        "            loss = (loss_i2t + loss_t2i) / 2.0\n",
        "            # implemented indirectly via cross-entropy on the similarity logits\n",
        "\n",
        "        # Compute gradients and update weights\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    def call(self, inputs):\n",
        "        images, texts = inputs\n",
        "        img_embeddings = tf.math.l2_normalize(self.image_encoder(images, training=False), axis=1)\n",
        "        txt_embeddings = tf.math.l2_normalize(self.text_encoder(texts, training=False), axis=1)\n",
        "        return img_embeddings, txt_embeddings"
      ],
      "metadata": {
        "id": "bFEfSXFhkuoq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip_model = CLIPModel(image_encoder, text_encoder, temperature=0.05)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "clip_model.compile(optimizer=optimizer)"
      ],
      "metadata": {
        "id": "Ps6-9P5nkw_S"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_embedding(text):\n",
        "    seq = tokenizer.texts_to_sequences([text])[0]\n",
        "    seq = tf.keras.preprocessing.sequence.pad_sequences([seq], maxlen=max_length, padding='post')\n",
        "    emb = text_encoder(seq, training=False)\n",
        "    emb = tf.math.l2_normalize(emb, axis=1)\n",
        "    return emb\n",
        "\n",
        "def get_image_embedding(image_path):\n",
        "    img = load_img(image_path, target_size=(image_size, image_size))\n",
        "    img = img_to_array(img) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    emb = image_encoder(img, training=False)\n",
        "    emb = tf.math.l2_normalize(emb, axis=1)\n",
        "    return emb\n",
        "\n",
        "test_image = 'xr.jpeg'\n",
        "img_emb = get_image_embedding(test_image)\n",
        "print(\"Image embedding:\", img_emb.numpy())\n",
        "\n",
        "all_reports = radiology_df['report'].tolist()\n",
        "all_text_embeddings = []\n",
        "for report in all_reports:\n",
        "    emb = get_text_embedding(report)\n",
        "    all_text_embeddings.append(emb.numpy()[0])\n",
        "all_text_embeddings = np.array(all_text_embeddings)\n",
        "\n",
        "cosine_sim = np.dot(all_text_embeddings, img_emb.numpy()[0])\n",
        "best_idx = np.argmax(cosine_sim)\n",
        "print(\"\\nBest matching report:\")\n",
        "print(all_reports[best_idx])"
      ],
      "metadata": {
        "id": "ak9AcSOLj9pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36db8514-59cc-4e13-e700-e43e442b30a8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image embedding: [[ 4.58757207e-03 -1.85515173e-03  7.45612383e-02  7.25065842e-02\n",
            "   1.66221466e-02 -2.87324633e-03 -5.97037449e-02  1.37557775e-01\n",
            "   1.30449524e-02  5.92132732e-02 -4.28169742e-02  4.54684123e-02\n",
            "  -8.52028206e-02  8.28145817e-02 -4.59460862e-04 -1.62412673e-02\n",
            "  -7.09518325e-03  9.07247663e-02 -6.81241322e-03  1.92373656e-02\n",
            "   1.66314647e-01 -9.75672230e-02 -5.61677106e-02 -1.52055919e-02\n",
            "   6.60163760e-02 -9.91720241e-03  1.62749160e-02  2.81153247e-03\n",
            "  -2.73268707e-02  9.44166109e-02 -1.82042867e-01  1.08924754e-01\n",
            "   9.03171003e-02  1.58348642e-02 -2.23294422e-02  1.87684987e-02\n",
            "   1.12209767e-01  1.28529752e-02  9.67474133e-02  7.89977014e-02\n",
            "   4.14035954e-02 -5.42617440e-02 -3.40365656e-02  2.78739748e-03\n",
            "  -2.37019304e-02  8.46468750e-03  5.94849251e-02 -3.54692340e-02\n",
            "   3.45325358e-02 -6.77166060e-02 -4.12244089e-02  2.02192329e-02\n",
            "   3.41784395e-02 -5.16678914e-02 -7.57371411e-02 -2.07511876e-02\n",
            "   7.67984092e-02 -2.04137545e-02 -1.44258458e-02 -1.13858260e-01\n",
            "   4.98172380e-02 -4.63846065e-02 -8.01597685e-02 -1.66848600e-02\n",
            "  -9.43076983e-02  9.15260687e-02  4.88545001e-02  1.43730855e-02\n",
            "   6.22346289e-02 -1.96244512e-02 -5.81490099e-02  1.00325318e-02\n",
            "  -2.95627285e-02  1.08090714e-02 -1.19443983e-01  2.47537326e-02\n",
            "   3.24891061e-02  1.84431467e-02 -2.50361953e-02 -6.95431978e-02\n",
            "  -1.02677651e-01 -1.08068600e-01  6.32923618e-02  2.00894978e-02\n",
            "   4.87566665e-02  7.10605923e-03  4.74391552e-03 -4.33975831e-02\n",
            "   5.15310429e-02 -8.57337639e-02  1.09310485e-02  4.20642458e-02\n",
            "  -8.89307410e-02  5.25587536e-02  2.85418658e-03  5.01381559e-03\n",
            "   7.21492758e-03  1.58663526e-01 -9.04498026e-02 -3.34268057e-04\n",
            "  -3.44982999e-03 -1.48841023e-01 -1.14021726e-01 -5.41504510e-02\n",
            "   5.03488742e-02  2.47502755e-02 -9.01237205e-02  8.24595392e-02\n",
            "  -2.41584908e-02 -4.30060774e-02  6.50368482e-02  2.15661004e-02\n",
            "   2.49733981e-02  2.98439395e-02  4.50947843e-02  4.76585366e-02\n",
            "  -3.89097556e-02 -2.79024206e-02 -9.93356034e-02 -2.85695749e-03\n",
            "  -3.84707446e-03 -3.03195696e-02 -4.46989387e-02 -3.40971886e-03\n",
            "  -6.97202608e-02  1.12630939e-02  1.00994832e-03 -1.24521516e-01\n",
            "   5.56820631e-02  2.93270983e-02  1.58953164e-02 -1.00251459e-01\n",
            "  -6.09414168e-02  1.10887207e-01 -1.05093271e-01  1.18100405e-01\n",
            "   9.20617580e-02  3.26155424e-02 -2.37881839e-02  6.33382006e-03\n",
            "   7.03279376e-02 -1.07584298e-01  5.86127788e-02  9.91111994e-02\n",
            "  -1.16868578e-02  8.33924338e-02  1.07935015e-02  5.41585386e-02\n",
            "   7.49509707e-02  8.32149351e-04 -7.00704530e-02  2.83593703e-02\n",
            "   6.11086935e-02 -9.43768844e-02 -7.75952339e-02 -7.51428157e-02\n",
            "   1.75058190e-02  4.22138209e-03  6.55905902e-02  3.22243087e-02\n",
            "  -5.82590736e-02 -5.36454134e-02  2.78870743e-02  3.24592963e-02\n",
            "   2.44332869e-02  3.13391685e-02  4.18205708e-02  8.66295248e-02\n",
            "  -5.75919226e-02 -4.31623980e-02  2.38604974e-02 -9.56389010e-02\n",
            "   7.40119964e-02  6.55855685e-02  1.09868474e-01  1.72557328e-02\n",
            "   1.61548443e-02 -2.45066565e-02 -8.70142281e-02  8.62554181e-03\n",
            "   4.61382009e-02  1.31348874e-02 -8.01561624e-02 -3.01373862e-02\n",
            "  -4.40545306e-02 -4.87188622e-02  5.66338450e-02  1.05035394e-01\n",
            "   3.70529816e-02 -4.36532982e-02  5.68577554e-03  1.50642172e-03\n",
            "   3.40841971e-02  4.92249131e-02  3.70527543e-02  3.81451771e-02\n",
            "   8.48624557e-02  2.18826216e-02  6.12811670e-02  5.12890108e-02\n",
            "   7.16174021e-02  9.79183912e-02  1.36013599e-02  6.17819391e-02\n",
            "   1.09313121e-02 -2.34188307e-02  4.58536856e-02 -5.89798614e-02\n",
            "  -2.17175614e-02  4.36554179e-02 -7.45876431e-02 -6.21520728e-02\n",
            "  -1.49466112e-01 -2.00320855e-02  5.08511327e-02  3.48118320e-02\n",
            "  -3.57917398e-02 -8.63570347e-02 -5.79125658e-02  7.22784027e-02\n",
            "   2.36900360e-03  3.61053869e-02  1.56147584e-01 -1.16607371e-05\n",
            "   1.84733025e-03  4.09198515e-02  1.55802350e-02  5.24273934e-03\n",
            "   3.54920700e-02 -7.89127573e-02  1.34701893e-01 -1.48723489e-02\n",
            "  -2.76753940e-02 -9.23969820e-02  2.62509156e-02  3.24511640e-02\n",
            "   3.76040000e-03 -1.74533203e-02 -4.70766984e-03 -1.60364628e-01\n",
            "  -3.77460644e-02 -1.59889571e-02 -6.10128678e-02  7.87586533e-03\n",
            "  -5.78699596e-02 -2.53642276e-02 -1.24090398e-02  6.25498891e-02\n",
            "   4.80029583e-02  5.31374775e-02 -5.88482339e-03 -7.92563409e-02\n",
            "   1.52566969e-01  8.51117224e-02  7.85319582e-02  1.32447332e-02]]\n",
            "\n",
            "Best matching report:\n",
            "FINDINGS: Chest. The trachea is midline. Negative for pneumothorax, pleural effusion or focal airspace consolidation. The heart size is normal. Abdomen. No pneumoperitoneum. There is a normal bowel XXXX pattern. Air and stool visible throughout the entire large colon including the rectum. No abnormally dilated small bowel loops. No evidence for intussusception or small bowel obstruction. No pathologic calcifications XXXX over the abdomen or pelvis. XXXX XXXX are without fracture or destructive lesion, though there are mild degenerative changes throughout the lumbar spine. Small hiatal hernia is not as well demonstrated on this exam.. IMPRESSION: Chest. 1. No acute cardiopulmonary abnormality. Abdomen. 1. No acute intra-abdominal process. Negative for obstruction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1 #you can increase it\n",
        "clip_model.fit(ds, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7_LT3KSk0Mp",
        "outputId": "21491711-830f-41f6-8d8f-6a7049785e59"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 965ms/step - loss: 2.7870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eef5d17f2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}